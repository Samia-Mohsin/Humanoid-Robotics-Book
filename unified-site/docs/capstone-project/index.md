# Capstone Project: The Autonomous Humanoid

## Project Overview
The capstone project brings together all the knowledge and skills learned throughout the course. Students will create a simulated humanoid robot that receives a voice command, plans a path, navigates obstacles, identifies an object using computer vision, and manipulates it.

## Project Goals
- Integrate all modules (ROS 2, Simulation, AI Brain, VLA) into a cohesive system
- Demonstrate conversational robotics with GPT models
- Implement complete perception-action pipeline
- Showcase embodied intelligence in physical space

## Project Phases

### Phase 1: Robot Design
- Design and configure the humanoid robot in simulation
- Set up URDF for the robot model
- Configure sensors (LiDAR, cameras, IMUs)
- Establish ROS 2 communication framework

### Phase 2: Locomotion
- Implement bipedal walking and balance control
- Develop path planning and navigation capabilities
- Integrate Nav2 for autonomous navigation
- Test locomotion in simulated environments

### Phase 3: Perception
- Implement computer vision for object identification
- Integrate VSLAM for environment mapping
- Develop obstacle detection and avoidance
- Create sensor fusion for environmental awareness

### Phase 4: Action and Interaction
- Integrate voice command recognition using Whisper
- Implement cognitive planning with LLMs
- Connect natural language understanding to ROS 2 actions
- Create manipulation and grasping capabilities

## Learning Outcomes
- Synthesize knowledge from all course modules
- Implement a complete robotic system
- Demonstrate embodied AI in action
- Practice interdisciplinary engineering

## Assessment Criteria
- Successful integration of all subsystems
- Reliable voice command recognition and execution
- Effective navigation and obstacle avoidance
- Quality of object identification and manipulation
- Presentation of project results and lessons learned

## Resources
- [ROS 2 Integration Guide](https://docs.ros.org/)
- [Simulation Best Practices](https://gazebosim.org/)
- [NVIDIA Isaac Tutorials](https://docs.nvidia.com/isaac/)
- [Voice Command Implementation](https://platform.openai.com/docs/guides/speech-to-text)

## Phases

- [Phase 1: Robot Design](./phase-1-robot-design)
- [Phase 2: Locomotion](./phase-2-locomotion)
- [Phase 3: Perception](./phase-3-perception)
- [Implementation Guide](./implementation-guide)